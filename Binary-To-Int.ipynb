{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Binary to Integer Generator\n",
    "def getInt(b_list):\n",
    "    binary = \"\"\n",
    "    for i in b_list:\n",
    "        binary += str(int(i))\n",
    "    return int(binary, 2)\n",
    "\n",
    "# Test case\n",
    "binary_number = [1, 0, 1]\n",
    "print getInt(binary_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  0.  0.] \t  12.0\n",
      "[ 1.  0.  0.  0.] \t  8.0\n",
      "[ 1.  0.  0.  1.] \t  9.0\n",
      "[ 0.  0.  1.  1.] \t  3.0\n",
      "[ 0.  1.  1.  0.] \t  6.0\n"
     ]
    }
   ],
   "source": [
    "# Dataset Creation\n",
    "def create_data(num_samples, len_binary):\n",
    "    x = np.zeros((num_samples, len_binary))\n",
    "    y = np.zeros(num_samples)\n",
    "    for i in range(num_samples):\n",
    "        x[i] = np.round(np.random.rand(len_binary)).astype(int)\n",
    "        y[i] = getInt(x[i])\n",
    "    return x, y\n",
    "\n",
    "# Test Case\n",
    "X, y = create_data(5, 4)\n",
    "for i in range(X.shape[0]):\n",
    "    print X[i], '\\t ', y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TF Model Parameters\n",
    "binary_length = 8\n",
    "training_samples = 1000\n",
    "testing_samples = 20\n",
    "lr = 0.01\n",
    "training_steps = 50000\n",
    "display_steps = 5000\n",
    "n_input = binary_length\n",
    "n_hidden_units = 16\n",
    "n_output = 1\n",
    "timestep = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  1.  1.  0.  1.  0.] \t154.0 \n",
      "\n",
      "[ 0.  1.  0.  1.  1.  1.  0.  0.] \t92.0 \n",
      "\n",
      "[ 1.  1.  0.  0.  0.  0.  1.  1.] \t195.0 \n",
      "\n",
      "[ 1.  1.  1.  0.  1.  1.  0.  0.] \t236.0 \n",
      "\n",
      "[ 1.  1.  0.  1.  0.  0.  1.  0.] \t210.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate Training and Testing Data\n",
    "X_train, y_train = create_data(training_samples, n_input)\n",
    "X_test, y_test = create_data(testing_samples, n_input)\n",
    "\n",
    "# Print data\n",
    "display = 5\n",
    "for i in range(display):\n",
    "    print X_train[i], '\\t', y_train[i], \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TF Model and intializations\n",
    "X = tf.placeholder(tf.float32, [None, timestep, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "W = tf.Variable(tf.random_normal([n_hidden_units, n_output]))\n",
    "b = tf.Variable(tf.random_normal([n_output]))\n",
    "\n",
    "def model(X, W, b, timestep, n_hidden_units):\n",
    "    X = tf.unstack(X, timestep, 1)\n",
    "    lstm_cell = rnn.BasicLSTMCell(n_hidden_units, forget_bias=1.0)\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "    logits = tf.matmul(outputs[-1], W) + b\n",
    "    return logits\n",
    "\n",
    "logits = model(X, W, b, timestep, n_hidden_units)\n",
    "loss = tf.reduce_mean(tf.losses.mean_squared_error(logits, y))\n",
    "optimizer = tf.train.RMSPropOptimizer(lr)\n",
    "training = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  1.  1.  0.  1.  0.]] \t[ 154.]\n",
      "[[ 0.  1.  0.  1.  1.  1.  0.  0.]] \t[ 92.]\n",
      "[[ 1.  1.  0.  0.  0.  0.  1.  1.]] \t[ 195.]\n",
      "[[ 1.  1.  1.  0.  1.  1.  0.  0.]] \t[ 236.]\n",
      "[[ 1.  1.  0.  1.  0.  0.  1.  0.]] \t[ 210.]\n"
     ]
    }
   ],
   "source": [
    "# Reshape data\n",
    "X_train = np.reshape(X_train, [-1, timestep, n_input])\n",
    "y_train = np.reshape(y_train, [-1, n_output])\n",
    "\n",
    "X_test = np.reshape(X_test, [-1, timestep, n_input])\n",
    "y_test = np.reshape(y_test, [-1, n_output])\n",
    "\n",
    "# Print data\n",
    "display = 5\n",
    "for i in range(display):\n",
    "    print X_train[i], '\\t', y_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 21405.0449219 at timestep 0 \n",
      "\n",
      "Loss 0.652780413628 at timestep 5000 \n",
      "\n",
      "Loss 0.425802528858 at timestep 10000 \n",
      "\n",
      "Loss 0.271017998457 at timestep 15000 \n",
      "\n",
      "Loss 0.221777930856 at timestep 20000 \n",
      "\n",
      "Loss 0.113618701696 at timestep 25000 \n",
      "\n",
      "Loss 0.0528116226196 at timestep 30000 \n",
      "\n",
      "Loss 0.0494224913418 at timestep 35000 \n",
      "\n",
      "Loss 0.0691263154149 at timestep 40000 \n",
      "\n",
      "Loss 0.0905301049352 at timestep 45000 \n",
      "\n",
      "Ground Truth \t Predicted\n",
      "[ 147.] -> [ 146.93043518]\n",
      "[ 48.] -> [ 47.8298378]\n",
      "[ 34.] -> [ 33.78536606]\n",
      "[ 245.] -> [ 244.96083069]\n",
      "[ 48.] -> [ 47.8298378]\n",
      "[ 10.] -> [ 9.8763113]\n",
      "[ 162.] -> [ 161.7947998]\n",
      "[ 244.] -> [ 243.83790588]\n",
      "[ 72.] -> [ 72.14963531]\n",
      "[ 211.] -> [ 211.0690918]\n",
      "[ 159.] -> [ 158.5680542]\n",
      "[ 88.] -> [ 87.89588928]\n",
      "[ 92.] -> [ 91.83252716]\n",
      "[ 228.] -> [ 228.25613403]\n",
      "[ 251.] -> [ 250.83132935]\n",
      "[ 162.] -> [ 161.7947998]\n",
      "[ 2.] -> [ 1.80910587]\n",
      "[ 57.] -> [ 56.99879456]\n",
      "[ 122.] -> [ 121.90625]\n",
      "[ 135.] -> [ 134.87109375]\n"
     ]
    }
   ],
   "source": [
    "# Run TF\n",
    "np.random.seed(0)\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for step in range(training_steps):\n",
    "        _, loss_out = sess.run([training, loss], feed_dict={X: X_train, y:y_train})\n",
    "        if step % display_steps == 0:\n",
    "            print \"Loss {} at timestep {} \\n\" .format(loss_out, step)\n",
    "    # Interpretting the results on test set\n",
    "    out = sess.run(logits, feed_dict={X: X_test})\n",
    "    plot = True \n",
    "    if plot is True:\n",
    "        print \"Ground Truth \\t Predicted\"\n",
    "        for i in range(testing_samples):\n",
    "            print y_test[i], \"->\", out[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metric\n",
    "# 1 if Prediction is close to ground truth (np.round)\n",
    "out_r = np.round_(out, decimals=0)\n",
    "acc = out_r == y_test\n",
    "acc = acc.sum()/float(len(y_test))\n",
    "print \"Accuracy is {}\" .format(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
